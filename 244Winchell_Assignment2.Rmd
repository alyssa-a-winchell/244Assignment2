---
title: 'ESM 244: Assignment 2'
author: "Alyssa Winchell"
date: "February 18, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Part 1: Data wrangling and visualization - cetaceans in captivity

Read in data:

```{r load}

cetacean <- read.csv("captive_cetacean.csv")

```

Load Packages:

```{r packages, echo = TRUE, warning=FALSE}

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(boot))

```

Data Wrangling:

```{r cetWrangle, warning=FALSE}

cap_rec <- cetacean %>%
  filter(acquisition == "Capture" | acquisition == "Rescue") %>%
  filter(status == "Alive") %>%
  select(species, birthYear, acquisition, originLocation, currently) %>%
  filter(birthYear != "NA")

cap_rec$navy <- str_detect(cap_rec$currently,"Navy") #does a given entry include "navy"" in its current location?

cap_rec$research <- str_detect(cap_rec$currently,"Research|Studies") #does a given entry include "Research" or "Studies" in its current location?

cap_rec$aquarium <- str_detect(cap_rec$currently,"Aquarium|Zoo") #does a given entry include "Aquarium" or "Zoo" in its current location?

cap_rec$sector = with(cap_rec, ifelse(navy %in% "TRUE", "Navy",
                  ifelse(research %in% "TRUE", "Research",
                  ifelse(aquarium %in% "TRUE", "Aquariums and Zoos", "Themeparks and Resorts")))) #creates a column for the sector that currently has the cetacean

cet_sector <- cap_rec %>%
  select(birthYear, acquisition, sector)

ThemeOnly <- cap_rec %>%
  filter(sector == "Themeparks and Resorts") #count how many cetaceans are in themeparks

navyOnly <- cap_rec %>%
  filter(navy == "TRUE") #count how many cetaceans are in the navy

ROnly <- cap_rec %>%
  filter(research == "TRUE") #count how many cetaceans are in research facilities

AOnly <- cap_rec %>%
  filter(aquarium == "TRUE") #count how many are in aquariums and zoos

```

Make a plot:

```{r cetGraph}

ggplot(data = cet_sector, aes(sector, fill = acquisition))+
  geom_bar(stat = "count") +
  theme_bw() +
  ylab("Number of Cetaceans") +
  xlab("Sector")

```

**Figure 1: Captured and Rescued Cetaceans in the US by Sector.** The number of wild-born cetaceans currently in caprtivity by aquariums and zoos (n = 14), the US navy (n = 28), research facilities (n = 8), and themeparks and resorts (n = 53), with captured cetaceans represented in red and rescued cetaceans represented in blue. Only cetaceans that were still alive and living in captivity as of May 7, 2017 were included in the data (n = 103).

### Part 2: Parameter Estimation – Wild Fish Catch

Load Data:

```{r}

fish <- read.csv("fish_catch_FIXED.csv")

```


a) Exploratory Graph

```{r explore}

ggplot(fish, aes(x = Year, y = Wild_Catch)) +
  geom_point()

```


b) This trend looks lie a logistic relationship between time and the amount of fish that are wild caught. Possible equation: N(t) = A/(1+Be^-rt)
$$Wild~Caught~Fish~(Time) = \frac{A}{1+Be^{-rt}}$$
- Estimate for K/A: ~ 73.4
- Estimate for N0: 17.2 (starting population)
- Estimate for B: ~ 4.058
- Estimate for r: ~ 0.03543

```{r}

BEstimate <- (87 - 17.2)/17.2
BEstimate #estimates and stores B

wild <- fish %>%
  select(Year, Wild_Catch)

#change year to # of years since 1950 so that 1950 is 0
wild$time = wild$Year - 1950

#estimate r by modeling as a logarithmic relationship when the catch is growing exponentially
log_time <- wild %>%
  filter(time < 38)

#plot cell growth vs time to make sure its linear
ggplot(log_time, aes(x = time, y = log(Wild_Catch)))+
  geom_point() #looks close to linear, which means that part was exp

lm(log(Wild_Catch) ~ time, data = log_time) # r ~ 0.03543

```

Find model A, B, and r using Gauss-Newton method for iterative convergence (nonlinear least squares):

Parameter Outcomes:
- A = 100 million tons of fish
- B = 4.32
- r = 0.0699 million tons per year

```{r nls}

fish_fit <- nls(Wild_Catch ~ A/(1 + B*exp(-r*time)),
                start = list(A = 73.4, B = 4.058, r = 0.03543),
                             data = wild,
                             trace = TRUE)

fish_fit

#store coeffs
A <- coef(fish_fit)[1]
B <- coef(fish_fit)[2]
r <- coef(fish_fit)[3]

#create a new seq of values that we want to make predictions for with model. New seq of time values of relevant times (time_seq)
time_seq <- seq(1,65)

#plug new seq into model with the parameters A, B , and r that were found:
fish_pred <- A/(1 + B*exp(-r*time_seq))

#bind together with original data (time_seq data):
pred_df <- data.frame(time_seq, fish_pred)

#create graph with original data and model preds:
ggplot(wild, aes(x = time, y = Wild_Catch)) +
  geom_point(color = "deeppink2", size = 3) +
  geom_line(data = pred_df, aes(x = time_seq, y = fish_pred), colour = "palegreen4", size = 1) +
  theme_bw() +
  xlab("Years Since 1950") +
  ylab("Fish Produced (Million Tons)") +
  ggtitle("Global Production of Wild Caught Fish (1950-2012)")

```


### Part 3: Bootstrapped Confidence Interval for Proportions

Recreate the Data:

```{r recreate}

yes <- rep.int(1, 22)
no <- rep.int(0,14)
response <- c(yes, no) 

students <-seq(1,36)
 
 nb <- data.frame(students,response)

```


Create Function and Bootsrap:

```{r bootstrap}

mean_fun <- function(x,i) {mean(x[i])} #i will be bootstrapping sample #, so x of bootstrap # to let it know that it will do the function for multiple times

boot_10thou <- boot(nb, mean_fun, R = 10000) #vector, function, R is how many bootstrapping samples

boot_10thou

ggplot() +
  aes(boot_10thou$t) +
  geom_histogram()

```

c)

### Part 4: Watch 3 RStudio::conf talks

1. *The Future's Shiny: Dashboards for Pioneering Genomic Medicine in R by Nic Crane*
- How shiny apps can be created for giant complex, databases for many users with different goals to ensure that data actually gets properly applied to real world problems.
- Good ideas for how to make metadata easily accessible in a shiny app (and in general).
- How does the company plan to make sure that the app is effective for all the different user needs?

2. *R at the ACLU: Joining tables to reunite families by Brooke Watson*
- How to deal with very messy data created by a large number of people and how to avoid major mistakes that could have let more children fall through the cracks.
- Regarding the large amount of missing data in this case: “The data we collect reflects what we value.” Brought up some of the challenges of working with uncooperative data sources and bureaucracies and what the missingness says about the values of the immigration policies.
- Were there any other ways you were able to catch errors in the data besides illogical timelines?

3. *Learning and using the tidyverse for historical research by Jesse Sadler*
- A nice example of another R beginner learning how to apply R to a field (history) that I usually don’t think of using coding.
- Goes over what it’s like to build your own package and what kind of problem you could be solving with an interesting historic example.
- How long did it take to build the package and how many functions does it have?
